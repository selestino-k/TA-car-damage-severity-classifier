{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "1976f8eb-cb22-4582-bcfb-e724809e7cf8",
    "_uuid": "5fe32d98-ce2b-49f2-8824-77bd250024bf",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "3b97d5c7-601a-42cd-ac30-f941d5275698",
    "_uuid": "63d1d04b-f102-4472-85ed-8b9e87b60bf5",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_dir = 'data3a/training' \n",
    "val_dir = 'data3a/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "77455093-dd58-4af4-9164-1bc4aa8d87ab",
    "_uuid": "27cb8398-82a6-4152-801e-1b3c80878f55",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "epoch = 50\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "f615c015-2008-441b-85f6-3201dd6591b9",
    "_uuid": "61332d13-6cc1-431c-9879-aa7b3094db57",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1383 images belonging to 3 classes.\n",
      "Found 248 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "dc0499ac-106e-43f9-87cd-7a8e7e4c294e",
    "_uuid": "9f945449-6f6a-4fa0-a9b0-fdf85b956e81",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "densenet121_model = Sequential()\n",
    "pretrained_model = DenseNet121(\n",
    "    include_top=False,\n",
    "    input_shape=(img_width, img_height, 3),\n",
    "    pooling='max',\n",
    "    classes=3,\n",
    "    weights='imagenet'\n",
    ")\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "densenet121_model.add(pretrained_model)\n",
    "densenet121_model.add(Flatten())\n",
    "densenet121_model.add(Dense(512, activation='relu'))\n",
    "# minor moderate and severe (3)\n",
    "densenet121_model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "a1737dea-68a7-4039-8f86-4712e21dd910",
    "_uuid": "a12f0062-0db5-4bc7-ab0e-54a9ecae6a88",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Model compile\n",
    "densenet121_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "# Define the CSVLogger\n",
    "\n",
    "log_folder = \"traininglog\"\n",
    "log_file_path = f\"{log_folder}/densenet121_training_log.csv\"\n",
    "\n",
    "csv_logger = CSVLogger(log_file_path, append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "976ce39a-32cb-4878-9987-8d5c58e628ff",
    "_uuid": "6abb7112-0c9a-49f9-81bf-6291911b8b7d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "87/87 [==============================] - 67s 705ms/step - loss: 2.1698 - accuracy: 0.4794 - val_loss: 1.5415 - val_accuracy: 0.4355\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 59s 675ms/step - loss: 1.0021 - accuracy: 0.5517 - val_loss: 0.9512 - val_accuracy: 0.5323\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 58s 671ms/step - loss: 0.8523 - accuracy: 0.6009 - val_loss: 0.8612 - val_accuracy: 0.6169\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 58s 671ms/step - loss: 0.8467 - accuracy: 0.6088 - val_loss: 0.7737 - val_accuracy: 0.6573\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 59s 675ms/step - loss: 0.8227 - accuracy: 0.6197 - val_loss: 0.7850 - val_accuracy: 0.6411\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 60s 692ms/step - loss: 0.7745 - accuracy: 0.6211 - val_loss: 0.8643 - val_accuracy: 0.5887\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 51s 581ms/step - loss: 0.8007 - accuracy: 0.6161 - val_loss: 0.7643 - val_accuracy: 0.6573\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 48s 557ms/step - loss: 0.7776 - accuracy: 0.6363 - val_loss: 0.8264 - val_accuracy: 0.5887\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 48s 548ms/step - loss: 0.7677 - accuracy: 0.6471 - val_loss: 0.7371 - val_accuracy: 0.6573\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 48s 557ms/step - loss: 0.7286 - accuracy: 0.6717 - val_loss: 0.8063 - val_accuracy: 0.6250\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 48s 552ms/step - loss: 0.7676 - accuracy: 0.6428 - val_loss: 0.8269 - val_accuracy: 0.5968\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 48s 550ms/step - loss: 0.7707 - accuracy: 0.6247 - val_loss: 0.8206 - val_accuracy: 0.5968\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 46s 527ms/step - loss: 0.7441 - accuracy: 0.6457 - val_loss: 0.7412 - val_accuracy: 0.6573\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 43s 498ms/step - loss: 0.7612 - accuracy: 0.6565 - val_loss: 0.7490 - val_accuracy: 0.6250\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 44s 501ms/step - loss: 0.7494 - accuracy: 0.6623 - val_loss: 0.8024 - val_accuracy: 0.6048\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 44s 501ms/step - loss: 0.7287 - accuracy: 0.6674 - val_loss: 0.7285 - val_accuracy: 0.6613\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 50s 571ms/step - loss: 0.7033 - accuracy: 0.6768 - val_loss: 0.7823 - val_accuracy: 0.6290\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 50s 570ms/step - loss: 0.7201 - accuracy: 0.6768 - val_loss: 0.7605 - val_accuracy: 0.6331\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 49s 562ms/step - loss: 0.7292 - accuracy: 0.6674 - val_loss: 0.7055 - val_accuracy: 0.6895\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 48s 547ms/step - loss: 0.7419 - accuracy: 0.6565 - val_loss: 0.8926 - val_accuracy: 0.5645\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 48s 555ms/step - loss: 0.7023 - accuracy: 0.6746 - val_loss: 0.7157 - val_accuracy: 0.6532\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 48s 548ms/step - loss: 0.7363 - accuracy: 0.6587 - val_loss: 0.7039 - val_accuracy: 0.6653\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 45s 515ms/step - loss: 0.7187 - accuracy: 0.6573 - val_loss: 0.7142 - val_accuracy: 0.6653\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 45s 520ms/step - loss: 0.7062 - accuracy: 0.6811 - val_loss: 0.7035 - val_accuracy: 0.6895\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 43s 499ms/step - loss: 0.6713 - accuracy: 0.6826 - val_loss: 0.7592 - val_accuracy: 0.6452\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 43s 498ms/step - loss: 0.6829 - accuracy: 0.6999 - val_loss: 0.7841 - val_accuracy: 0.6331\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 44s 507ms/step - loss: 0.6973 - accuracy: 0.6963 - val_loss: 0.8799 - val_accuracy: 0.5685\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 44s 507ms/step - loss: 0.6693 - accuracy: 0.6913 - val_loss: 0.8811 - val_accuracy: 0.5605\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 45s 519ms/step - loss: 0.6400 - accuracy: 0.7108 - val_loss: 0.8034 - val_accuracy: 0.6250\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 43s 495ms/step - loss: 0.6517 - accuracy: 0.7021 - val_loss: 0.8644 - val_accuracy: 0.6008\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 44s 510ms/step - loss: 0.6621 - accuracy: 0.7014 - val_loss: 0.8199 - val_accuracy: 0.5968\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 44s 504ms/step - loss: 0.6825 - accuracy: 0.6862 - val_loss: 0.7782 - val_accuracy: 0.6371\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 46s 529ms/step - loss: 0.6564 - accuracy: 0.7043 - val_loss: 0.7902 - val_accuracy: 0.6250\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 44s 503ms/step - loss: 0.6486 - accuracy: 0.7050 - val_loss: 0.8342 - val_accuracy: 0.6048\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 44s 506ms/step - loss: 0.6283 - accuracy: 0.7035 - val_loss: 0.7637 - val_accuracy: 0.6371\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 44s 503ms/step - loss: 0.6373 - accuracy: 0.7079 - val_loss: 0.7516 - val_accuracy: 0.6452\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 44s 504ms/step - loss: 0.6259 - accuracy: 0.7289 - val_loss: 0.8971 - val_accuracy: 0.6008\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 43s 500ms/step - loss: 0.6358 - accuracy: 0.7021 - val_loss: 0.7943 - val_accuracy: 0.6169\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 45s 512ms/step - loss: 0.6282 - accuracy: 0.7108 - val_loss: 0.8198 - val_accuracy: 0.6492\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 43s 497ms/step - loss: 0.6339 - accuracy: 0.7129 - val_loss: 0.8778 - val_accuracy: 0.6008\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 44s 510ms/step - loss: 0.6223 - accuracy: 0.7129 - val_loss: 0.8390 - val_accuracy: 0.6008\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 45s 516ms/step - loss: 0.6255 - accuracy: 0.7223 - val_loss: 0.8788 - val_accuracy: 0.6008\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 44s 511ms/step - loss: 0.6135 - accuracy: 0.7440 - val_loss: 1.0270 - val_accuracy: 0.5968\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 45s 522ms/step - loss: 0.6200 - accuracy: 0.7187 - val_loss: 0.8381 - val_accuracy: 0.6331\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 46s 527ms/step - loss: 0.5928 - accuracy: 0.7289 - val_loss: 0.7876 - val_accuracy: 0.6331\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 45s 518ms/step - loss: 0.5798 - accuracy: 0.7426 - val_loss: 0.8295 - val_accuracy: 0.6452\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 43s 499ms/step - loss: 0.5852 - accuracy: 0.7419 - val_loss: 0.8810 - val_accuracy: 0.6210\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 43s 495ms/step - loss: 0.5841 - accuracy: 0.7440 - val_loss: 0.8836 - val_accuracy: 0.6452\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 43s 493ms/step - loss: 0.5845 - accuracy: 0.7455 - val_loss: 0.8491 - val_accuracy: 0.6411\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 42s 481ms/step - loss: 0.5750 - accuracy: 0.7542 - val_loss: 0.8946 - val_accuracy: 0.6089\n",
      "Total training time: 2357.56 seconds\n"
     ]
    }
   ],
   "source": [
    "set_epoch=50\n",
    "#Model Train \n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model and pass the CSVLogger as a callback\n",
    "history = densenet121_model.fit(train_generator, epochs=set_epoch, validation_data=val_generator,callbacks=[csv_logger])\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Total training time: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "13056a71-50e5-454e-aaae-cf90038ed9a5",
    "_uuid": "c4dd384d-4206-403f-8e0b-5211b75c06e4",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "from sklearn.metrics import f1_score\n",
    "# # f1 score\n",
    "# plt.plot(history.history['f1_score'], label='Training F1 Score')\n",
    "# plt.plot(history.history['val_f1_score'], label='Validation F1 Score')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('F1 Score')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "val_images, val_labels = [], []\n",
    "class_names = sorted(train_generator.class_indices.keys())\n",
    "for i in range(len(val_generator)):\n",
    "    images, labels = val_generator[i]\n",
    "    val_images.extend(images)\n",
    "    val_labels.extend(np.argmax(labels, axis=1))\n",
    "\n",
    "\n",
    "val_images = np.array(val_images)\n",
    "val_labels = np.array(val_labels)\n",
    "\n",
    "predictions = densenet121_model.predict(val_images)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = val_labels\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_true, y_pred)\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(confusion_matrix, cmap='Reds')\n",
    "\n",
    "cbar = fig.colorbar(cax)\n",
    "\n",
    "ax.set_xlabel('predicted') #predicted\n",
    "ax.set_ylabel('actual') #actual\n",
    "\n",
    "ax.set_xticklabels([''] + ['minor', 'moderate', 'severe'], rotation=45) #predicted\n",
    "ax.set_yticklabels([''] + ['minor', 'moderate', 'severe']) #actual\n",
    "\n",
    "for i in range(confusion_matrix.shape[0]):\n",
    "    for j in range(confusion_matrix.shape[1]):\n",
    "        ax.text(j, i, str(confusion_matrix[i, j]), ha='center', va='center')\n",
    "print('Confusion Matrix:')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1199e544-d350-4408-bb01-4143021050c4",
    "_uuid": "0eee6ed9-6498-4738-90fc-c91a71497a86",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "densenet_model.save('densenet121-model.keras')\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = 'data3a/validation'\n",
    "class_names = [\"01-minor\", \"02-moderate\", \"03-severe\"]\n",
    "\n",
    "image_paths = []\n",
    "for class_name in class_names:\n",
    "    folder_path = os.path.join(val_dir, class_name)\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_paths.append(os.path.join(folder_path, filename))\n",
    "negative = 0\n",
    "positive = 0\n",
    "for image_path in image_paths:\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path)\n",
    "    img = img.resize((img_width, img_height))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    pred = densenet121_model.predict(img)\n",
    "    pred_label = class_names[np.argmax(pred)]\n",
    "    folder_name = os.path.basename(os.path.dirname(image_path))\n",
    "    plt.imshow(img[0])\n",
    "    if (pred_label != folder_name):\n",
    "        plt.title('Pred: ' + pred_label + ' Actl: ' + folder_name, color = 'red')\n",
    "        negative+=1\n",
    "    else:\n",
    "        plt.title('Pred: ' + pred_label + ' Actl: ' + folder_name, color = 'green')\n",
    "        positive+=1\n",
    "   \n",
    "    plt.axis('off')\n",
    "    plt.show() \n",
    "print('False: '+ str(negative) + '\\nTrue: ' + str(positive))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
